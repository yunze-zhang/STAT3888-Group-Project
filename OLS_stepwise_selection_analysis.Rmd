---
title: "Feasibility Analysis"
output: html_document
---


```{r Preprocessing, warning = FALSE, message = FALSE, include = FALSE}
library(tidyverse)
library(skimr)
library(visdat)
library(GGally)
library(knitr)
library(corrplot)
library(glmnet)
library(brglm)
library(jtools)
```

```{r}
install.packages('ggstance')
```


```{r Preprocessing, warning = FALSE, message = FALSE, include = FALSE}
combined_data = read.csv('PC_combined_data.csv')
```

```{r Viewing combined data, warning = FALSE}
class(combined_data)
DT::datatable(combined_data)
```

```{r Viewing Systolic blood pressure, warning = FALSE}
systol_data=combined_data[ , !(names(combined_data) %in% c("ABSPID", "ABSHID", "BMISC", "HCHOLBC", "CHOLRESB", "CHOLNTR", "HDLCHREB", "LDLNTR", "LDLRESB", "DIASTOL", "HSUGBC", "BMR", "EIBMR1", "EIBMR2"))]
# How/why did you choose to omit these particular variables?

# These are our response variables - those we decided we would use to predict cardiovascular health with. If I don't remove them, they'd become predictor variables in the linear models I use later on. 



class(systol_data)
DT::datatable(systol_data)
```

```{r Correlation plot of variables}
M = cor(systol_data)
corrplot(M, method = 'color', order = 'alphabet') 
```


```{r Initial null and full models}
systol_M0 = lm(SYSTOL ~ 1, data = systol_data)
systol_M1 = lm(SYSTOL ~ ., data = systol_data)
```

```{r Forward AIC on null model}
systol_forw <- step(systol_M0, scope = list(lower = systol_M0, upper = systol_M1), direction = "forward", k = 2, trace = 0)

summary(systol_forw)
```

```{r}
plot_summs(systol_forw, sort)
```



### The stuff from here onwards was me trying to play with getting ridge regression working in R. It didnt come out as I expected so I redid everything in python which worked out better.

```{r Created GLM}

y = systol_data$SYSTOL
x = combined_data[ , !(names(combined_data) %in% c("ABSPID", "ABSHID", "BMISC", "SYSTOL", "HCHOLBC", "CHOLRESB", "CHOLNTR", "HDLCHREB", "LDLNTR", "LDLRESB", "DIASTOL", "HSUGBC", "BMR", "EIBMR1", "EIBMR2"))]
# Once again where do these variables come from? (I haven't done any lectures yet, is this concept from it?)

model <- glmnet(x, y, alpha = 0) # purpose of this variable? (We aren't using it anywhere)
# Alpha determines if we want LASSO or RIDGE regression. I think I tested ridge regression here.

best_lambda = model$lambda.min

best_model <- glmnet(x, y, alpha = 0, lambda = best_lambda) # How do we find this best_lambda? 
# Oops, must have accidentally deleted the line. 

summary(best_model)
```

```{r}
summary(y)
```

```{r Predict Systolic blood pressure levels using the GLM}
y_predicted <- predict(model, s = best_lambda, newx = x)
sst <- sum((y - mean(y))^2)
sse <- sum((y_predicted - y)^2)
rsq <- 1 - sse/sst
rsq
```
```{r}
r2 = brglm(y~x)
summary(r2)
```

